{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUvyB0ku3IOg"
   },
   "source": [
    "Quora Insincere Question _data augmentation by replacing with similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nZGG4C_4AVe"
   },
   "outputs": [],
   "source": [
    "CSV_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3273,
     "status": "ok",
     "timestamp": 1571984282500,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "OJ4AQfLU4CO6",
    "outputId": "c99f44fe-924a-4007-e9bb-8315c349cbee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q2d8OdW4CRu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Activation, GRU\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4EE7ZGos4CVy"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1571984282505,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "43KjpUDe4_KG",
    "outputId": "2eaa0e23-b636-4683-a406-0ab69d18ff2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46926,
     "status": "ok",
     "timestamp": 1571984330473,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "r-SOqkgd_wf4",
    "outputId": "3b9abfc7-c888-4d5c-fc10-02765bd9a42c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43487,
     "status": "ok",
     "timestamp": 1571984330475,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "luzibgTS-SSp",
    "outputId": "273db1e7-2baa-4dd7-9d89-f0a4fa562803"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('father', 0.8199654221534729), ('mother', 0.8136025071144104)]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['woman', 'king'], topn=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704955,
     "status": "ok",
     "timestamp": 1571974027750,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "4AbW-nXk4Cam",
    "outputId": "c641a56f-dad7-4dca-ee1b-a0e3140771c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100% ||                                      | Time:  0:11:42   2.1 MiB/s\n"
     ]
    }
   ],
   "source": [
    "#This code snippet is inspired by https://github.com/chakki-works/chakin\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from progressbar import Bar, ETA, FileTransferSpeed, ProgressBar, Percentage, RotatingMarker\n",
    "\n",
    "\n",
    "ROOT_DIR = './'\n",
    "url = 'http://nlp.stanford.edu/data/glove.twitter.27B.zip'\n",
    "file_name = url.split('/')[-1]\n",
    "save_path = os.path.join(ROOT_DIR, file_name)\n",
    "\n",
    "widgets = ['Test: ', Percentage(), ' ', Bar(marker=RotatingMarker()), ' ', ETA(), ' ', FileTransferSpeed()]\n",
    "pbar = ProgressBar(widgets=widgets)\n",
    "\n",
    "def dlProgress(count, blockSize, totalSize):\n",
    "    if pbar.max_value is None:\n",
    "        pbar.max_value = totalSize\n",
    "        pbar.start()\n",
    "\n",
    "    pbar.update(min(count * blockSize, totalSize))\n",
    "\n",
    "path, _ = urlretrieve(url, save_path, reporthook=dlProgress)\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 90369,
     "status": "ok",
     "timestamp": 1571974311909,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "uLD4ga6v4Cf2",
    "outputId": "1ad673e0-19c1-4b2a-b30a-4d30668143d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip ./glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oO5aWAp4Ck9"
   },
   "outputs": [],
   "source": [
    "def load_glove_simple(word_dict):#word_index {'word': index} dictionary\n",
    "    EMBEDDING_FILE = './glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    word_index = word_dict\n",
    "    nb_words = len(word_index)+1\n",
    "    \n",
    "\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size),dtype=np.float32) - 1.\n",
    "    \n",
    "    for key, i in tqdm(word_index.items()):\n",
    "        word = key\n",
    "        embedding_vector = embeddings_index.get(word)        \n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = key.lower()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = key.upper()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = key.capitalize()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "            \n",
    "    del embeddings_index\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    return embedding_matrix, nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37442,
     "status": "ok",
     "timestamp": 1571984334014,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "3u79bK5O4CtY",
    "outputId": "bf04deee-4e2c-4503-809e-34e83c3b65a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(CSV_PATH, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(CSV_PATH, 'test.csv'))\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mFMLymH4CzZ"
   },
   "outputs": [],
   "source": [
    "train_X = train_df[\"question_text\"].fillna(\" \")\n",
    "test_X = test_df[\"question_text\"].fillna(\" \")\n",
    "train_y = train_df['target'].values\n",
    "bool_train_labels = train_y != 0\n",
    "#text_list = pd.concat([train_X,test_X]).apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjdlzf_EFsuf"
   },
   "outputs": [],
   "source": [
    "max_features = 95000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwKx2QijFTPf"
   },
   "outputs": [],
   "source": [
    "def create_dict(neg_vocab,embedding_model,max_iter=None, threshold=0.5,topn=1):\n",
    "    dict={}\n",
    "    if max_iter is not None:\n",
    "        it = min(len(neg_vocab), max_iter)\n",
    "        for idx, word  in tqdm(enumerate(neg_vocab)):\n",
    "            if idx > it:\n",
    "                break\n",
    "      \n",
    "            try:\n",
    "                word = word.lower()\n",
    "                embedding_model[word]\n",
    "                pos = pos_tag([word])\n",
    "                replacements = embedding_model.most_similar(positive = word, topn=topn)\n",
    "                replacements = [r for r in replacements if r[1]>threshold ]\n",
    "                replacements = [r for r in replacements if pos_tag([r[0]])[0][1] == pos[0][1]]\n",
    "                dict.update({word:replacements}) if len(replacements)>0 else dict\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        for word  in tqdm(neg_vocab):\n",
    "            try:\n",
    "                word = word.lower()\n",
    "                embedding_model[word]\n",
    "                pos = pos_tag([word])\n",
    "                replacements = embedding_model.most_similar(positive = word, topn=topn)\n",
    "                replacements = [r for r in replacements if r[1]>threshold ]\n",
    "                replacements = [r for r in replacements if pos_tag([r[0]])[0][1] == pos[0][1]]\n",
    "                dict.update({word:replacements}) if len(replacements)>0 else dict\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wriXuYl_FTVn"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_df[bool_train_labels].question_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQ27ncffFTMe"
   },
   "outputs": [],
   "source": [
    "positive_sample_vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 778796,
     "status": "ok",
     "timestamp": 1571985094811,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "g1uCcDO-FTEY",
    "outputId": "2b3a87cb-0049-46e8-bbc4-c1546660f855"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42512 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "100%|██████████| 42512/42512 [12:38<00:00, 56.02it/s]\n"
     ]
    }
   ],
   "source": [
    "augment_vocab = create_dict(positive_sample_vocab, word_vectors, topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9M9d2SKtJjjW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json = json.dumps(augment_vocab)\n",
    "f = open(\"./augment_dict.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2zeDR9FYm9O"
   },
   "outputs": [],
   "source": [
    "positive_samples = list(train_df[bool_train_labels].question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xOZrjpiZZmL"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def augment_sentence(augmented_dict, sentence):\n",
    "    aug=[]\n",
    "    for word in sentence:\n",
    "        if word in augmented_dict:\n",
    "            replace = augmented_dict[word][0]\n",
    "            if replace[1] > random.random():\n",
    "                aug.append(replace[0])\n",
    "            else:\n",
    "                aug.append(word)\n",
    "        else:\n",
    "            aug.append(word)\n",
    "            \n",
    "    return ' '.join(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1154,
     "status": "ok",
     "timestamp": 1571986780102,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "T6RpMU-fYeZ3",
    "outputId": "b5f6a761-2180-4176-cbc8-98689fd9e210"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80810/80810 [00:00<00:00, 135595.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def augment(sentences, augmented_dict):\n",
    "    augmented=[]\n",
    "    for sen in tqdm(sentences):\n",
    "        aug = augment_sentence(augmented_dict, sen.split())\n",
    "        augmented.append(aug)\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "augmented_sentences = augment(positive_samples, augment_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6vFB658ShSh"
   },
   "outputs": [],
   "source": [
    "positive_labels = [1]*len(augmented_sentences)\n",
    "\n",
    "augmented_df = pd.DataFrame(list(zip(augmented_sentences,positive_labels)), columns=['question_text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1571986817458,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "20_9A-DTf7HD",
    "outputId": "e98f7d6c-b4fc-4581-fa4a-daecb9a82bd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has this United States become this biggest dic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which infants are more sweeter to their parent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If whites support college choice and requireme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am gay girl and I love your nephew (boy). He...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which races have this smallest penis?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  target\n",
       "0  Has this United States become this biggest dic...       1\n",
       "1  Which infants are more sweeter to their parent...       1\n",
       "2  If whites support college choice and requireme...       1\n",
       "3  I am gay girl and I love your nephew (boy). He...       1\n",
       "4              Which races have this smallest penis?       1"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2K5dUwhDkuij"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, augmented_df], join='inner', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8REHclp8l1ge"
   },
   "outputs": [],
   "source": [
    "text_list = pd.concat([train_X,test_X]).apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lPjnwA84Cxi"
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.08, stratify=train_df['target'] ,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAEde2aC4Crt"
   },
   "outputs": [],
   "source": [
    "\n",
    "#train_X = np.array(train_df.pop('question_text')) --> This might help to save memory\n",
    "train_X = train_df['question_text'].fillna(\" \")\n",
    "val_X = val_df['question_text'].fillna(\" \")\n",
    "test_X = test_df['question_text'].fillna(\" \")\n",
    "\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values\n",
    "\n",
    "bool_train_labels = train_y != 0\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(text_list))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xrupz1Fp4Cpb"
   },
   "outputs": [],
   "source": [
    "train_X_pad = pad_sequences(train_X, maxlen=100,padding='post')\n",
    "val_X_pad = pad_sequences(val_X, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCTmR-XD4CjD"
   },
   "outputs": [],
   "source": [
    "dataset_v1_train = tf.data.Dataset.from_tensor_slices((train_X_pad, train_y)).shuffle(10000).batch(256)\n",
    "dataset_v1_val = tf.data.Dataset.from_tensor_slices((val_X_pad, val_y)).shuffle(10000).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21jVx7iO4Cd1"
   },
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    stop = len(train_X)\n",
    "    i = 0\n",
    "    while i < stop:\n",
    "        yield np.array(train_X[i]), np.array(train_y[i])\n",
    "        i += 1\n",
    "    \n",
    "dataset_v2 = tf.data.Dataset.from_generator(data_generator, output_types=(tf.int32,tf.int32), output_shapes=((None), ()))\n",
    "padded_dataset_v2 = dataset_v2.padded_batch(16, padded_shapes=((None,), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWOFg4qpvbwM"
   },
   "outputs": [],
   "source": [
    "a = np.arange(1,21,1).reshape(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYwuffbc_hGt"
   },
   "outputs": [],
   "source": [
    "choice = np.random.random(a.shape[0])< 0.5\n",
    "a[choice] = a[choice] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1571991536297,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "ZC1T68la_hk8",
    "outputId": "d73c667b-bf9c-41a7-ec0a-400ddb54b8f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 102, 103, 104, 105],\n",
       "       [106, 107, 108, 109, 110],\n",
       "       [ 11,  12,  13,  14,  15],\n",
       "       [216, 217, 218, 219, 220]])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucNZrqRC_xU_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Kaggle - data augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
